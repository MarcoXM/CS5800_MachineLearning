{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({1: 900, 0: 100})\n",
      "Resampled dataset shape Counter({0: 900, 1: 900})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80, 1)"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE # doctest: +NORMALIZE_WHITESPACE\n",
    "X, y = make_classification(n_classes=2, class_sep=2,\n",
    "weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,\n",
    "n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\n",
    "print('Original dataset shape %s' % Counter(y))\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcowang/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/marcowang/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "col = ['target','F1R','F1S','F2R','F2S','F3R','F3S','F4R','F4S','F5R','F5S','F6R','F6S','F7R','F7S','F8R','F8S','F9R','F9S','F10R','F10S',\n",
    "      'F11R','F11S','F12R','F12S','F13R','F13S','F14R','F14S','F15R','F15S','F16R','F16S','F17R','F17S','F18R','F18S',\n",
    "      'F19R','F19S','F20R','F20S','F21R','F21S','F22R','F22S']\n",
    "\n",
    "train = pd.read_csv('data/SPECTF_train.csv', header=None, low_memory=False,names = col,)\n",
    "train.head()\n",
    "test = pd.read_csv('data/SPECTF_test.csv', header=None, low_memory=False,names = col)\n",
    "\n",
    "import numpy as np\n",
    "scaler = StandardScaler()\n",
    "y_train = train['target'].values.reshape(-1,1)\n",
    "X = train.drop('target',axis = 1).values\n",
    "test_y = test['target'].values.reshape(-1,1)\n",
    "test_x = test.drop('target',axis = 1).values\n",
    "X_std = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcowang/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80, 44)"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_b,y_b = sm.fit_resample(X_std, y_train)\n",
    "\n",
    "X_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-487-634f77e5af6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "X_std.dot(nn.weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Function\n",
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    z = Z[:]\n",
    "    z[z<0] = 0\n",
    "    return z\n",
    "\n",
    "def sigmoid_backward(sig):\n",
    "    return (sig * (1 - sig))\n",
    "\n",
    "def relu_backward(Z):\n",
    "    dZ = Z.copy()\n",
    "    dZ[dZ > 0] = 1\n",
    "\n",
    "    return dZ;\n",
    "\n",
    "def step(Z):\n",
    "    Z[Z>=0] = 1\n",
    "    Z[Z<0] = 0\n",
    "    return Z\n",
    "\n",
    "\n",
    "def tanh(Z):\n",
    "    return (np.exp(2*Z) -1)/(np.exp(2*Z) +1)\n",
    "\n",
    "def tanh_backward(tan):\n",
    "    return (1 - tan**2)\n",
    "class NN(object):\n",
    "    def __init__(self, n_input, n_output,actfun = 'sigmoid'):\n",
    "        np.random.seed(1224)\n",
    "        self.weights = np.random.randn(n_input,n_output)*0.1\n",
    "        self.bias = np.random.randn(n_output,1) * 0.1\n",
    "        self.activation = actfun\n",
    "        \n",
    "        \n",
    "    # Computing the ouput of the neurons\n",
    "    def forward(self,inputx):\n",
    "        if self.activation == 'sigmoid':\n",
    "            return sigmoid(np.dot(inputx,self.weights) + self.bias)\n",
    "        \n",
    "        if self.activation == 'step':\n",
    "            return step(np.dot(inputx,self.weights)+ self.bias)\n",
    "        \n",
    "        if self.activation == 'tanh':\n",
    "            return tanh(np.dot(inputx,self.weights)+ self.bias)\n",
    "        \n",
    "        if self.activation == 'relu':\n",
    "            return relu(np.dot(inputx,self.weights)+ self.bias) \n",
    "        \n",
    "    def loss(self,X_train,y_train):\n",
    "        self.output = self.forward(X_train)\n",
    "        #print(self.output.shape)\n",
    "        self.error = y_train - self.output\n",
    "        return np.mean(self.error**2)\n",
    "    \n",
    "    def backward(self,X_train, y_train,learnrate):\n",
    "        if self.activation == 'sigmoid':\n",
    "            self.weights += np.sum(learnrate * self.error * sigmoid_backward(X_train,self.output),axis =0).reshape(-1,1)\n",
    "            self.bias += np.sum(learnrate * self.error * sigmoid_backward(1,self.output))\n",
    "  \n",
    "       # if self.activation == 'step':\n",
    "           # self.weights += np.sum(learnrate * self.error * sigmoid_backward(X_train,self.output),axis =0).reshape(-1,1)\n",
    "          #  self.bias += np.sum(learnrate * self.error * sigmoid_backward(1,self.output))\n",
    "\n",
    "        if self.activation == 'tanh':\n",
    "            self.weights += np.sum(learnrate * self.error * tanh_backward(X_train,self.output),axis =0).reshape(-1,1)\n",
    "            self.bias += np.sum(learnrate * self.error * tanh_backward(1,self.output))\n",
    "            \n",
    "        if self.activation == 'relu':\n",
    "            self.weights += np.sum(learnrate * self.error * relu_backward(X_train,self.output),axis =0).reshape(-1,1)\n",
    "            self.bias += np.sum(learnrate * self.error * relu_backward(1,self.output))\n",
    "            \n",
    "    def train(self,X_train,y_train,learnrate, iteration = 100):\n",
    "        for i in range(iteration):\n",
    "            self.loss(X_train,y_train)\n",
    "            self.backward(X_train,y_train,learnrate)\n",
    "            \n",
    "    def preidict(self,X,y):\n",
    "        y_pre = step(self.forward(X))\n",
    "        acc = list(y-y_pre)\n",
    "        return acc.count(0)/len(acc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 1)"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn3 = NN(44,1,actfun='tanh')\n",
    "out = nn3.forward(X_std)\n",
    "error=y_train - out\n",
    "error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-490-9925583da9fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtanh_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_std\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'c' is not defined"
     ]
    }
   ],
   "source": [
    "(error*tanh_backward(X_std,c)*0.001).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tanh'"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn3.activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-492-9e88759db7ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mLEARNINGRATE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_std\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnn3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_std\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLEARNINGRATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "LEARNINGRATE = .001\n",
    "b = nn3.forward(X_std) * (1- nn.forward(X_std))\n",
    "nn3.train(X_std,y_train,LEARNINGRATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11764705882352944"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- nn3.preidict(test_x,test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 1), (187, 3))"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.output_weights.shape,mm.out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_initial(m,n): # xiviar initial\n",
    "    weights= np.random.randn(m, n) / np.sqrt(m)\n",
    "    bias = np.random.randn(1, n) / np.sqrt(m)\n",
    "    return weights,bias\n",
    "        \n",
    "class MN(object):\n",
    "    def __init__(self,n_feature, n_input,n_hidden, n_output,activation = 'sigmoid'): # 3 matrix\n",
    "        np.random.seed(224)\n",
    "        self.input_weights,self.input_bias = weight_initial(n_feature, n_input) #m x l1\n",
    "        self.hidden_weights,self.hidden_bias = weight_initial(n_input,n_hidden) # l1 x l2\n",
    "        self.output_weights,self.output_bias = weight_initial(n_hidden, n_output) # l2 x l3\n",
    "        self.activation = activation\n",
    "        \n",
    "    def forward(self,inputx):\n",
    "        if self.activation == 'sigmoid':\n",
    "            self.out1 = sigmoid(np.dot(inputx,self.input_weights) + self.input_bias)\n",
    "            self.out2 = sigmoid(np.dot(self.out1,self.hidden_weights) + self.hidden_bias)\n",
    "            self.out3 = sigmoid(np.dot(self.out2,self.output_weights) + self.output_bias)\n",
    "            #print(self.out3)\n",
    "        \n",
    "        if self.activation == 'step':\n",
    "            self.out1 = step(np.dot(inputx,self.input_weights) + self.input_bias)\n",
    "            self.out2 = step(np.dot(self.out1,self.hidden_weights) + self.hidden_bias)\n",
    "            self.out3 = step(np.dot(self.out2,self.output_weights) + self.output_bias)\n",
    "            \n",
    "        if self.activation == 'tanh':\n",
    "            self.out1 = tanh(np.dot(inputx,self.input_weights) + self.input_bias)\n",
    "            self.out2 = tanh(np.dot(self.out1,self.hidden_weights) + self.hidden_bias)\n",
    "            self.out3 = tanh(np.dot(self.out2,self.output_weights) + self.output_bias)\n",
    "            \n",
    "        if self.activation == 'relu':\n",
    "            self.out1 = relu(np.dot(inputx,self.input_weights) + self.input_bias)\n",
    "            self.out2 = relu(np.dot(self.out1,self.hidden_weights) + self.hidden_bias)\n",
    "            self.out3 = relu(np.dot(self.out2,self.output_weights) + self.output_bias)\n",
    "    \n",
    "    def loss(self,X_train,y_train):\n",
    "        self.forward(X_train)\n",
    "        self.error3 = y_train - self.out3\n",
    "        self.error2 = np.mean(self.error3 * self.output_weights.T,axis = 0).reshape(1,-1)\n",
    "        self.error1 = self.error2.dot(self.hidden_weights.T)\n",
    "        return np.mean(self.error3**2)\n",
    "            \n",
    "    def backward(self,inputx, y_train,learnrate):\n",
    "        if self.activation == 'sigmoid':\n",
    "            error3_ = np.mean(self.error3,axis=0)\n",
    "            self.output_weights += learnrate * error3_ * self.out2.T.dot(sigmoid_backward(self.out3))\n",
    "            self.output_bias += np.sum(learnrate * error3_ * sigmoid_backward(self.out3))\n",
    "            \n",
    "            self.hidden_weights += learnrate * (self.error2 * self.out1.T.dot(sigmoid_backward(self.out2)))\n",
    "            self.hidden_bias += np.sum(learnrate * self.error2 * (sigmoid_backward(self.out2)),axis =0)\n",
    "            \n",
    "            self.input_weights += learnrate * self.error1 * inputx.T.dot(sigmoid_backward(self.out1))\n",
    "            self.input_bias += np.sum(learnrate * self.error1 * sigmoid_backward(self.out1),axis = 0)\n",
    "            \n",
    "            \n",
    "        if self.activation == 'tanh':\n",
    "            error3_ = np.mean(self.error3,axis=0)\n",
    "            self.output_weights += learnrate * error3_ * self.out2.T.dot(tanh_backward(self.out3))\n",
    "            self.output_bias += np.sum(learnrate * error3_ * tanh_backward(self.out3))\n",
    "            \n",
    "            self.hidden_weights += learnrate * (self.error2 * self.out1.T.dot(tanh_backward(self.out2)))\n",
    "            self.hidden_bias += np.sum(learnrate * self.error2 * (tanh_backward(self.out2)),axis =0)\n",
    "            \n",
    "            self.input_weights += learnrate * self.error1 * inputx.T.dot(tanh_backward(self.out1))\n",
    "            self.input_bias += np.sum(learnrate * self.error1 * tanh_backward(self.out1),axis = 0)\n",
    "            \n",
    "        \n",
    "        if self.activation == 'relu':\n",
    "            error3_ = np.mean(self.error3,axis=0)\n",
    "            self.output_weights += learnrate * error3_ * self.out2.T.dot(relu_backward(self.out3))\n",
    "            self.output_bias += np.sum(learnrate * error3_ * relu_backward(self.out3))\n",
    "            \n",
    "            self.hidden_weights += learnrate * (self.error2 * self.out1.T.dot(relu_backward(self.out2)))\n",
    "            self.hidden_bias += np.sum(learnrate * self.error2 * (relu_backward(self.out2)),axis =0)\n",
    "            \n",
    "            self.input_weights += learnrate * self.error1 * inputx.T.dot(relu_backward(self.out1))\n",
    "            self.input_bias += np.sum(learnrate * self.error1 * relu_backward(self.out1),axis = 0)\n",
    "            \n",
    "            \n",
    "            \n",
    "       \n",
    "            \n",
    "    def train(self,X_train,y_train,learnrate, iteration = 100):\n",
    "        self.losses = []\n",
    "        for i in range(iteration):\n",
    "            self.loss(X_train,y_train)\n",
    "            self.backward(X_train,y_train,learnrate)\n",
    "            if i % 100 ==0:\n",
    "                self.losses.append(self.loss(X_train,y_train))\n",
    "                print('Epoch: ', str(i) +'| ' +str(iteration), '| train loss: %.4f' % self.losses[-1])\n",
    "                \n",
    "            \n",
    "    def predict(self,X,y):\n",
    "        self.forward(X)\n",
    "        y_pre = step(self.out3)\n",
    "        #print(y_pre)\n",
    "        acc = list(y-y_pre)\n",
    "        print(classification_report(y,y_pre))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 263,
       "width": 406
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = ['A', 'B', 'C', 'D']\n",
    "#for i, l_his in enumerate(mm.losses):\n",
    "plt.plot(mm.losses, label=' ')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim((0.25, .2535555))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0| 1500 | train loss: 0.2517\n",
      "Epoch:  100| 1500 | train loss: 0.2508\n",
      "Epoch:  200| 1500 | train loss: 0.2507\n",
      "Epoch:  300| 1500 | train loss: 0.2506\n",
      "Epoch:  400| 1500 | train loss: 0.2506\n",
      "Epoch:  500| 1500 | train loss: 0.2506\n",
      "Epoch:  600| 1500 | train loss: 0.2506\n",
      "Epoch:  700| 1500 | train loss: 0.2506\n",
      "Epoch:  800| 1500 | train loss: 0.2506\n",
      "Epoch:  900| 1500 | train loss: 0.2506\n",
      "Epoch:  1000| 1500 | train loss: 0.2506\n",
      "Epoch:  1100| 1500 | train loss: 0.2506\n",
      "Epoch:  1200| 1500 | train loss: 0.2506\n",
      "Epoch:  1300| 1500 | train loss: 0.2506\n",
      "Epoch:  1400| 1500 | train loss: 0.2506\n",
      "0:00:00.358818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.92      1.00      0.96       172\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       187\n",
      "   macro avg       0.46      0.50      0.48       187\n",
      "weighted avg       0.85      0.92      0.88       187\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcowang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "mm = MN(44,1,3,1,activation='sigmoid')\n",
    "mm.train(X_std,y_train,0.001,iteration = 1500)\n",
    "endtime = datetime.datetime.now()\n",
    "print((endtime - starttime))\n",
    "mm.predict(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49660482],\n",
       "       [ 0.50376067],\n",
       "       [ 0.50518487],\n",
       "       [ 0.50010729],\n",
       "       [ 0.49965505],\n",
       "       [ 0.49362897],\n",
       "       [ 0.49844059],\n",
       "       [ 0.49842739],\n",
       "       [ 0.49713297],\n",
       "       [ 0.50516043],\n",
       "       [ 0.50012258],\n",
       "       [ 0.50005305],\n",
       "       [ 0.50474418],\n",
       "       [ 0.5019647 ],\n",
       "       [ 0.50285126],\n",
       "       [ 0.50245355],\n",
       "       [ 0.50573861],\n",
       "       [ 0.50009349],\n",
       "       [ 0.49889898],\n",
       "       [ 0.50410278],\n",
       "       [ 0.49307165],\n",
       "       [ 0.49908123],\n",
       "       [ 0.49636801],\n",
       "       [ 0.49120732],\n",
       "       [ 0.49272112],\n",
       "       [ 0.50467265],\n",
       "       [ 0.50498522],\n",
       "       [ 0.50597604],\n",
       "       [ 0.50143883],\n",
       "       [ 0.49911126],\n",
       "       [ 0.50083278],\n",
       "       [ 0.50507913],\n",
       "       [ 0.5063136 ],\n",
       "       [ 0.50181139],\n",
       "       [ 0.49646153],\n",
       "       [ 0.50126346],\n",
       "       [ 0.49951149],\n",
       "       [ 0.50510238],\n",
       "       [ 0.49694985],\n",
       "       [ 0.50231317],\n",
       "       [-0.5057105 ],\n",
       "       [-0.50333734],\n",
       "       [-0.49924008],\n",
       "       [-0.4978564 ],\n",
       "       [-0.49691933],\n",
       "       [-0.50129007],\n",
       "       [-0.49776774],\n",
       "       [-0.49911787],\n",
       "       [-0.50148312],\n",
       "       [-0.49599122],\n",
       "       [-0.50247229],\n",
       "       [-0.49931521],\n",
       "       [-0.49537127],\n",
       "       [-0.50305305],\n",
       "       [-0.50496309],\n",
       "       [-0.5000242 ],\n",
       "       [-0.50063617],\n",
       "       [-0.49377401],\n",
       "       [-0.50212372],\n",
       "       [-0.50094447],\n",
       "       [-0.49883887],\n",
       "       [-0.50524954],\n",
       "       [-0.49905631],\n",
       "       [-0.50511066],\n",
       "       [-0.50205031],\n",
       "       [-0.50346077],\n",
       "       [-0.49675921],\n",
       "       [-0.50207944],\n",
       "       [-0.49515079],\n",
       "       [-0.50398913],\n",
       "       [-0.49764361],\n",
       "       [-0.50129259],\n",
       "       [-0.5043929 ],\n",
       "       [-0.49826669],\n",
       "       [-0.49608374],\n",
       "       [-0.50114938],\n",
       "       [-0.50629214],\n",
       "       [-0.50119105],\n",
       "       [-0.50285481],\n",
       "       [-0.50109832]])"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.error3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 1), (3, 187))"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.output_weights.shape,mm.out2.T.shape,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stucture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=44, out_features=1000, bias=True)\n",
      "  (out): Linear(in_features=1000, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(torch.nn.Module):     # 继承 torch 的 Module\n",
    "    def __init__(self, n_feature, n_hidden, n_output): # 45in \n",
    "        super(Net, self).__init__()     # 继承 __init__ 功能\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # 隐藏层线性输出\n",
    "        self.out = torch.nn.Linear(n_hidden, n_output)       # 输出层线性输出\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 正向传播输入值, 神经网络分析出输出值\n",
    "        x = F.relu(self.hidden(x))      # 激励函数(隐藏层的线性值)\n",
    "        x = self.out(x)                 # 输出值, 但是这个不是预测值, 预测值还需要再另外计算\n",
    "        return x\n",
    "\n",
    "net = Net(n_feature=44, n_hidden=1000, n_output=2) # 几个类别就几个 output\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=44, out_features=1, bias=True)\n",
      "  (1): Dropout(p=0.5)\n",
      "  (2): Sigmoid()\n",
      "  (3): Linear(in_features=1, out_features=3, bias=True)\n",
      "  (4): Dropout(p=0.5)\n",
      "  (5): Sigmoid()\n",
      "  (6): Linear(in_features=3, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcowang/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/marcowang/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as Data\n",
    "tensor_data = torch.from_numpy(X_std)\n",
    "tensor_data = tensor_data.float()\n",
    "tensor_target = torch.from_numpy(y_train)\n",
    "\n",
    "test_x = scaler.fit_transform(test_x)\n",
    "test_x = torch.from_numpy(test_x)\n",
    "test_x = test_x.float()\n",
    "\n",
    "\n",
    "torch_dataset = Data.TensorDataset(tensor_data, tensor_target)\n",
    "loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,      # torch TensorDataset format\n",
    "    batch_size=BATCH_SIZE,      # mini batch size\n",
    "    shuffle=True,               # 要不要打乱数据 (打乱比较好)   \n",
    ")\n",
    "\n",
    "\n",
    "net2 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(44, 1),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(1, 3),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(3, 2),\n",
    ")\n",
    "print(net2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "multi-target not supported at /Users/soumith/mc3build/conda-bld/pytorch_1549593514549/work/aten/src/THNN/generic/ClassNLLCriterion.c:21",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-510-aa41fe318df7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;31m#  output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# cross entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# clear gradients for this training step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;31m# backpropagation, compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 904\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1970\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1788\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1789\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: multi-target not supported at /Users/soumith/mc3build/conda-bld/pytorch_1549593514549/work/aten/src/THNN/generic/ClassNLLCriterion.c:21"
     ]
    }
   ],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 1500          #\n",
    "BATCH_SIZE = 80     # whole dataset\n",
    "LR = 0.001         # learning rate\n",
    "\n",
    "optimizer = torch.optim.SGD(net2.parameters(), lr=LR)\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(EPOCH):   # 训练所有!整套!数据 50000次\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        output = net2(batch_x)               #  output\n",
    "        loss = loss_func(output, batch_y)   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "    if epoch % 100 == 0:\n",
    "        test_output = net2(test_x)                   # (samples, time_step, input_size)\n",
    "        pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "        accuracy = float((pred_y == test_y).astype(int).sum()) / float(test_y.size)\n",
    "        print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation (sigmoid) function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))\n",
    "def error_formula(y, output):\n",
    "    return - y*np.log(output) - (1 - y) * np.log(1-output)\n",
    "def error_term_formula(x, y, output):\n",
    "    return (y - output)*sigmoid_prime(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network hyperparameters\n",
    "epochs = 1000\n",
    "learnrate = 0.5\n",
    "\n",
    "# Training function\n",
    "def train_nn(features, targets, epochs, learnrate):\n",
    "    \n",
    "    # Use to same seed to make debugging easier\n",
    "    np.random.seed(42)\n",
    "\n",
    "    n_records, n_features = features.shape\n",
    "    last_loss = None\n",
    "\n",
    "    # Initialize weights\n",
    "    weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        del_w = np.zeros(weights.shape)\n",
    "        for x, y in zip(features.values, targets):\n",
    "            # Loop through all records, x is the input, y is the target\n",
    "\n",
    "            # Activation of the output unit\n",
    "            #   Notice we multiply the inputs and the weights here \n",
    "            #   rather than storing h as a separate variable \n",
    "            output = sigmoid(np.dot(x, weights))\n",
    "\n",
    "            # The error, the target minus the network output\n",
    "            error = error_formula(y, output)\n",
    "\n",
    "            # The error term\n",
    "            error_term = error_term_formula(x, y, output)\n",
    "\n",
    "            # The gradient descent step, the error times the gradient times the inputs\n",
    "            del_w += error_term * x\n",
    "\n",
    "        # Update the weights here. The learning rate times the \n",
    "        # change in weights, divided by the number of records to average\n",
    "        weights += learnrate * del_w / n_records\n",
    "\n",
    "        # Printing out the mean square error on the training set\n",
    "        if e % (epochs / 10) == 0:\n",
    "            out = sigmoid(np.dot(features, weights))\n",
    "            loss = np.mean((out - targets) ** 2)\n",
    "            print(\"Epoch:\", e)\n",
    "            if last_loss and last_loss < loss:\n",
    "                print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "            else:\n",
    "                print(\"Train loss: \", loss)\n",
    "            last_loss = loss\n",
    "            print(\"=========\")\n",
    "    print(\"Finished training!\")\n",
    "    return weights\n",
    "    \n",
    "#weights = train_nn(features, targets, epochs, learnrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy on test data\n",
    "test_out = sigmoid(np.dot(features_test, weights))\n",
    "predictions = test_out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
