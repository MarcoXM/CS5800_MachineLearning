{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stucture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_structure = [\n",
    "    {\"input_dim\": 2, \"output_dim\": 4, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 4, \"output_dim\": 6, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 6, \"output_dim\": 6, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 6, \"output_dim\": 4, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 4, \"output_dim\": 1, \"activation\": \"sigmoid\"}, # Because this is a binary classification problem.\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layers(nn_structure,seed = 224):\n",
    "    np.random.seed(224)\n",
    "    num_layers = len(nn_structure)\n",
    "    para_values = {}\n",
    "    for i, v in enumerate(nn_structure):\n",
    "        layer_index = i + 1\n",
    "        layer_in = v['input_dim']\n",
    "        layer_out = v['output_dim']\n",
    "        para_values['W' + str(layer_index)] = np.random.randn(\n",
    "            layer_out, layer_in) * 0.1\n",
    "        para_values['b' + str(layer_index)] = np.random.randn(\n",
    "            layer_out, 1) * 0.1\n",
    "    return para_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.max(0,Z)\n",
    "\n",
    "def sigmoid_backward(dx, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dx * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dx, Z):\n",
    "    dZ = np.array(dx, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   target  F1R  F1S  F2R  F2S  F3R  F3S  F4R  F4S  F5R  ...   F18R  F18S  \\\n",
       " 0       1   67   68   73   78   65   63   67   60   63  ...     61    56   \n",
       " 1       1   75   74   71   71   62   58   70   64   71  ...     66    62   \n",
       " 2       1   83   64   66   67   67   74   74   72   64  ...     67    64   \n",
       " 3       1   72   66   65   65   64   61   71   78   73  ...     69    68   \n",
       " 4       1   62   60   69   61   63   63   70   68   70  ...     66    66   \n",
       " \n",
       "    F19R  F19S  F20R  F20S  F21R  F21S  F22R  F22S  \n",
       " 0    76    75    74    77    76    74    59    68  \n",
       " 1    68    69    69    66    64    58    57    52  \n",
       " 2    69    63    68    54    65    64    43    42  \n",
       " 3    68    63    71    72    65    63    58    60  \n",
       " 4    58    56    72    73    71    64    49    42  \n",
       " \n",
       " [5 rows x 45 columns], (187, 45))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = ['target','F1R','F1S','F2R','F2S','F3R','F3S','F4R','F4S','F5R','F5S','F6R','F6S','F7R','F7S','F8R','F8S','F9R','F9S','F10R','F10S',\n",
    "      'F11R','F11S','F12R','F12S','F13R','F13S','F14R','F14S','F15R','F15S','F16R','F16S','F17R','F17S','F18R','F18S',\n",
    "      'F19R','F19S','F20R','F20S','F21R','F21S','F22R','F22S']\n",
    "\n",
    "train = pd.read_csv('data/SPECTF_train.csv', header=None, low_memory=False,names = col,)\n",
    "train.head()\n",
    "test = pd.read_csv('data/SPECTF_test.csv', header=None, low_memory=False,names = col)\n",
    "test.head(),test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=44, out_features=1000, bias=True)\n",
      "  (out): Linear(in_features=1000, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(torch.nn.Module):     # 继承 torch 的 Module\n",
    "    def __init__(self, n_feature, n_hidden, n_output): # 45in \n",
    "        super(Net, self).__init__()     # 继承 __init__ 功能\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # 隐藏层线性输出\n",
    "        self.out = torch.nn.Linear(n_hidden, n_output)       # 输出层线性输出\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 正向传播输入值, 神经网络分析出输出值\n",
    "        x = F.relu(self.hidden(x))      # 激励函数(隐藏层的线性值)\n",
    "        x = self.out(x)                 # 输出值, 但是这个不是预测值, 预测值还需要再另外计算\n",
    "        return x\n",
    "\n",
    "net = Net(n_feature=44, n_hidden=1000, n_output=2) # 几个类别就几个 output\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "scaler = StandardScaler()\n",
    "y = train['target'].values\n",
    "X = train.drop('target',axis = 1).values\n",
    "test_y = test['target'].values\n",
    "test_x = test.drop('target',axis = 1).values\n",
    "X_std = scaler.fit_transform(X)\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 50          # 训练整批数据多少次, 为了节约时间, 我们只训练一次\n",
    "BATCH_SIZE = 20     # 20\n",
    "LR = 0.0005           # learning rate\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.02)\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "import torch.utils.data as Data\n",
    "tensor_data = torch.from_numpy(X_std)\n",
    "tensor_data = tensor_data.float()\n",
    "tensor_target = torch.from_numpy(y)\n",
    "\n",
    "test_x = scaler.fit_transform(test_x)\n",
    "test_x = torch.from_numpy(test_x)\n",
    "test_x = test_x.float()\n",
    "\n",
    "\n",
    "torch_dataset = Data.TensorDataset(tensor_data, tensor_target)\n",
    "loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,      # torch TensorDataset format\n",
    "    batch_size=BATCH_SIZE,      # mini batch size\n",
    "    shuffle=True,               # 要不要打乱数据 (打乱比较好)   \n",
    ")\n",
    "\n",
    "\n",
    "net2 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(44, 300),\n",
    "    torch.nn.Dropout(0.3),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(300, 500),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(500, 30),\n",
    "    torch.nn.Dropout(0.3),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(30, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.6828 | test accuracy: 0.21\n",
      "Epoch:  1 | train loss: 0.7013 | test accuracy: 0.24\n",
      "Epoch:  2 | train loss: 0.7396 | test accuracy: 0.28\n",
      "Epoch:  3 | train loss: 0.7051 | test accuracy: 0.26\n",
      "Epoch:  4 | train loss: 0.7002 | test accuracy: 0.26\n",
      "Epoch:  5 | train loss: 0.7238 | test accuracy: 0.20\n",
      "Epoch:  6 | train loss: 0.6966 | test accuracy: 0.25\n",
      "Epoch:  7 | train loss: 0.6790 | test accuracy: 0.21\n",
      "Epoch:  8 | train loss: 0.7337 | test accuracy: 0.26\n",
      "Epoch:  9 | train loss: 0.6946 | test accuracy: 0.26\n",
      "Epoch:  10 | train loss: 0.6960 | test accuracy: 0.30\n",
      "Epoch:  11 | train loss: 0.7198 | test accuracy: 0.29\n",
      "Epoch:  12 | train loss: 0.7268 | test accuracy: 0.26\n",
      "Epoch:  13 | train loss: 0.6891 | test accuracy: 0.23\n",
      "Epoch:  14 | train loss: 0.6927 | test accuracy: 0.23\n",
      "Epoch:  15 | train loss: 0.6978 | test accuracy: 0.28\n",
      "Epoch:  16 | train loss: 0.6949 | test accuracy: 0.28\n",
      "Epoch:  17 | train loss: 0.6959 | test accuracy: 0.26\n",
      "Epoch:  18 | train loss: 0.6924 | test accuracy: 0.24\n",
      "Epoch:  19 | train loss: 0.6873 | test accuracy: 0.21\n",
      "Epoch:  20 | train loss: 0.6788 | test accuracy: 0.29\n",
      "Epoch:  21 | train loss: 0.7093 | test accuracy: 0.24\n",
      "Epoch:  22 | train loss: 0.6842 | test accuracy: 0.26\n",
      "Epoch:  23 | train loss: 0.6847 | test accuracy: 0.27\n",
      "Epoch:  24 | train loss: 0.7045 | test accuracy: 0.28\n",
      "Epoch:  25 | train loss: 0.6808 | test accuracy: 0.27\n",
      "Epoch:  26 | train loss: 0.7054 | test accuracy: 0.29\n",
      "Epoch:  27 | train loss: 0.7039 | test accuracy: 0.27\n",
      "Epoch:  28 | train loss: 0.7004 | test accuracy: 0.25\n",
      "Epoch:  29 | train loss: 0.6748 | test accuracy: 0.22\n",
      "Epoch:  30 | train loss: 0.7102 | test accuracy: 0.24\n",
      "Epoch:  31 | train loss: 0.6863 | test accuracy: 0.24\n",
      "Epoch:  32 | train loss: 0.6749 | test accuracy: 0.26\n",
      "Epoch:  33 | train loss: 0.6856 | test accuracy: 0.24\n",
      "Epoch:  34 | train loss: 0.7224 | test accuracy: 0.26\n",
      "Epoch:  35 | train loss: 0.6935 | test accuracy: 0.17\n",
      "Epoch:  36 | train loss: 0.7155 | test accuracy: 0.28\n",
      "Epoch:  37 | train loss: 0.6990 | test accuracy: 0.29\n",
      "Epoch:  38 | train loss: 0.6839 | test accuracy: 0.26\n",
      "Epoch:  39 | train loss: 0.7230 | test accuracy: 0.23\n",
      "Epoch:  40 | train loss: 0.6813 | test accuracy: 0.23\n",
      "Epoch:  41 | train loss: 0.6990 | test accuracy: 0.23\n",
      "Epoch:  42 | train loss: 0.6853 | test accuracy: 0.27\n",
      "Epoch:  43 | train loss: 0.7060 | test accuracy: 0.25\n",
      "Epoch:  44 | train loss: 0.6872 | test accuracy: 0.24\n",
      "Epoch:  45 | train loss: 0.7074 | test accuracy: 0.24\n",
      "Epoch:  46 | train loss: 0.7081 | test accuracy: 0.28\n",
      "Epoch:  47 | train loss: 0.6990 | test accuracy: 0.27\n",
      "Epoch:  48 | train loss: 0.7020 | test accuracy: 0.32\n",
      "Epoch:  49 | train loss: 0.7011 | test accuracy: 0.22\n",
      "Epoch:  0 | train loss: 0.7029 | test accuracy: 0.25\n",
      "Epoch:  1 | train loss: 0.6964 | test accuracy: 0.22\n",
      "Epoch:  2 | train loss: 0.6979 | test accuracy: 0.26\n",
      "Epoch:  3 | train loss: 0.7095 | test accuracy: 0.24\n",
      "Epoch:  4 | train loss: 0.6957 | test accuracy: 0.27\n",
      "Epoch:  5 | train loss: 0.7053 | test accuracy: 0.27\n",
      "Epoch:  6 | train loss: 0.7041 | test accuracy: 0.22\n",
      "Epoch:  7 | train loss: 0.7008 | test accuracy: 0.22\n",
      "Epoch:  8 | train loss: 0.6808 | test accuracy: 0.26\n",
      "Epoch:  9 | train loss: 0.6935 | test accuracy: 0.27\n",
      "Epoch:  10 | train loss: 0.6968 | test accuracy: 0.28\n",
      "Epoch:  11 | train loss: 0.6935 | test accuracy: 0.23\n",
      "Epoch:  12 | train loss: 0.6774 | test accuracy: 0.26\n",
      "Epoch:  13 | train loss: 0.6870 | test accuracy: 0.27\n",
      "Epoch:  14 | train loss: 0.7221 | test accuracy: 0.28\n",
      "Epoch:  15 | train loss: 0.6938 | test accuracy: 0.25\n",
      "Epoch:  16 | train loss: 0.6788 | test accuracy: 0.26\n",
      "Epoch:  17 | train loss: 0.6867 | test accuracy: 0.26\n",
      "Epoch:  18 | train loss: 0.7118 | test accuracy: 0.28\n",
      "Epoch:  19 | train loss: 0.7040 | test accuracy: 0.26\n",
      "Epoch:  20 | train loss: 0.6733 | test accuracy: 0.33\n",
      "Epoch:  21 | train loss: 0.7083 | test accuracy: 0.26\n",
      "Epoch:  22 | train loss: 0.6977 | test accuracy: 0.26\n",
      "Epoch:  23 | train loss: 0.6806 | test accuracy: 0.25\n",
      "Epoch:  24 | train loss: 0.6973 | test accuracy: 0.25\n",
      "Epoch:  25 | train loss: 0.6898 | test accuracy: 0.24\n",
      "Epoch:  26 | train loss: 0.6996 | test accuracy: 0.21\n",
      "Epoch:  27 | train loss: 0.7031 | test accuracy: 0.28\n",
      "Epoch:  28 | train loss: 0.6992 | test accuracy: 0.22\n",
      "Epoch:  29 | train loss: 0.6837 | test accuracy: 0.24\n",
      "Epoch:  30 | train loss: 0.7104 | test accuracy: 0.24\n",
      "Epoch:  31 | train loss: 0.7018 | test accuracy: 0.22\n",
      "Epoch:  32 | train loss: 0.6842 | test accuracy: 0.25\n",
      "Epoch:  33 | train loss: 0.7055 | test accuracy: 0.24\n",
      "Epoch:  34 | train loss: 0.7079 | test accuracy: 0.25\n",
      "Epoch:  35 | train loss: 0.6834 | test accuracy: 0.26\n",
      "Epoch:  36 | train loss: 0.6844 | test accuracy: 0.26\n",
      "Epoch:  37 | train loss: 0.7125 | test accuracy: 0.22\n",
      "Epoch:  38 | train loss: 0.6763 | test accuracy: 0.22\n",
      "Epoch:  39 | train loss: 0.6898 | test accuracy: 0.27\n",
      "Epoch:  40 | train loss: 0.6817 | test accuracy: 0.23\n",
      "Epoch:  41 | train loss: 0.6802 | test accuracy: 0.24\n",
      "Epoch:  42 | train loss: 0.6878 | test accuracy: 0.21\n",
      "Epoch:  43 | train loss: 0.7136 | test accuracy: 0.25\n",
      "Epoch:  44 | train loss: 0.6977 | test accuracy: 0.26\n",
      "Epoch:  45 | train loss: 0.7061 | test accuracy: 0.26\n",
      "Epoch:  46 | train loss: 0.7196 | test accuracy: 0.26\n",
      "Epoch:  47 | train loss: 0.6880 | test accuracy: 0.25\n",
      "Epoch:  48 | train loss: 0.7035 | test accuracy: 0.26\n",
      "Epoch:  49 | train loss: 0.7047 | test accuracy: 0.22\n",
      "Epoch:  0 | train loss: 0.7015 | test accuracy: 0.29\n",
      "Epoch:  1 | train loss: 0.7076 | test accuracy: 0.29\n",
      "Epoch:  2 | train loss: 0.7033 | test accuracy: 0.20\n",
      "Epoch:  3 | train loss: 0.6833 | test accuracy: 0.25\n",
      "Epoch:  4 | train loss: 0.7081 | test accuracy: 0.21\n",
      "Epoch:  5 | train loss: 0.6897 | test accuracy: 0.28\n",
      "Epoch:  6 | train loss: 0.7073 | test accuracy: 0.22\n",
      "Epoch:  7 | train loss: 0.7074 | test accuracy: 0.29\n",
      "Epoch:  8 | train loss: 0.6774 | test accuracy: 0.24\n",
      "Epoch:  9 | train loss: 0.6998 | test accuracy: 0.18\n",
      "Epoch:  10 | train loss: 0.6918 | test accuracy: 0.26\n",
      "Epoch:  11 | train loss: 0.6957 | test accuracy: 0.26\n",
      "Epoch:  12 | train loss: 0.7001 | test accuracy: 0.29\n",
      "Epoch:  13 | train loss: 0.7028 | test accuracy: 0.22\n",
      "Epoch:  14 | train loss: 0.6914 | test accuracy: 0.25\n",
      "Epoch:  15 | train loss: 0.6974 | test accuracy: 0.22\n",
      "Epoch:  16 | train loss: 0.6908 | test accuracy: 0.22\n",
      "Epoch:  17 | train loss: 0.7099 | test accuracy: 0.27\n",
      "Epoch:  18 | train loss: 0.7074 | test accuracy: 0.25\n",
      "Epoch:  19 | train loss: 0.7015 | test accuracy: 0.27\n",
      "Epoch:  20 | train loss: 0.6903 | test accuracy: 0.22\n",
      "Epoch:  21 | train loss: 0.7052 | test accuracy: 0.20\n",
      "Epoch:  22 | train loss: 0.6788 | test accuracy: 0.19\n",
      "Epoch:  23 | train loss: 0.6943 | test accuracy: 0.24\n",
      "Epoch:  24 | train loss: 0.6961 | test accuracy: 0.25\n",
      "Epoch:  25 | train loss: 0.7050 | test accuracy: 0.25\n",
      "Epoch:  26 | train loss: 0.7022 | test accuracy: 0.27\n",
      "Epoch:  27 | train loss: 0.7198 | test accuracy: 0.27\n",
      "Epoch:  28 | train loss: 0.7158 | test accuracy: 0.24\n",
      "Epoch:  29 | train loss: 0.6961 | test accuracy: 0.27\n",
      "Epoch:  30 | train loss: 0.6919 | test accuracy: 0.23\n",
      "Epoch:  31 | train loss: 0.6874 | test accuracy: 0.25\n",
      "Epoch:  32 | train loss: 0.6805 | test accuracy: 0.27\n",
      "Epoch:  33 | train loss: 0.7067 | test accuracy: 0.22\n",
      "Epoch:  34 | train loss: 0.6850 | test accuracy: 0.25\n",
      "Epoch:  35 | train loss: 0.6833 | test accuracy: 0.25\n",
      "Epoch:  36 | train loss: 0.7120 | test accuracy: 0.26\n",
      "Epoch:  37 | train loss: 0.7137 | test accuracy: 0.20\n",
      "Epoch:  38 | train loss: 0.6853 | test accuracy: 0.27\n",
      "Epoch:  39 | train loss: 0.6896 | test accuracy: 0.26\n",
      "Epoch:  40 | train loss: 0.7126 | test accuracy: 0.21\n",
      "Epoch:  41 | train loss: 0.6949 | test accuracy: 0.24\n",
      "Epoch:  42 | train loss: 0.7045 | test accuracy: 0.28\n",
      "Epoch:  43 | train loss: 0.6950 | test accuracy: 0.25\n",
      "Epoch:  44 | train loss: 0.7111 | test accuracy: 0.21\n",
      "Epoch:  45 | train loss: 0.7035 | test accuracy: 0.26\n",
      "Epoch:  46 | train loss: 0.7033 | test accuracy: 0.26\n",
      "Epoch:  47 | train loss: 0.7198 | test accuracy: 0.27\n",
      "Epoch:  48 | train loss: 0.6730 | test accuracy: 0.24\n",
      "Epoch:  49 | train loss: 0.7039 | test accuracy: 0.20\n",
      "Epoch:  0 | train loss: 0.7087 | test accuracy: 0.25\n",
      "Epoch:  1 | train loss: 0.6891 | test accuracy: 0.25\n",
      "Epoch:  2 | train loss: 0.6798 | test accuracy: 0.23\n",
      "Epoch:  3 | train loss: 0.6952 | test accuracy: 0.25\n",
      "Epoch:  4 | train loss: 0.7126 | test accuracy: 0.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5 | train loss: 0.6662 | test accuracy: 0.26\n",
      "Epoch:  6 | train loss: 0.6859 | test accuracy: 0.26\n",
      "Epoch:  7 | train loss: 0.6907 | test accuracy: 0.22\n",
      "Epoch:  8 | train loss: 0.7150 | test accuracy: 0.25\n",
      "Epoch:  9 | train loss: 0.6777 | test accuracy: 0.22\n",
      "Epoch:  10 | train loss: 0.6806 | test accuracy: 0.28\n",
      "Epoch:  11 | train loss: 0.7072 | test accuracy: 0.20\n",
      "Epoch:  12 | train loss: 0.6854 | test accuracy: 0.19\n",
      "Epoch:  13 | train loss: 0.7111 | test accuracy: 0.26\n",
      "Epoch:  14 | train loss: 0.6931 | test accuracy: 0.16\n",
      "Epoch:  15 | train loss: 0.7188 | test accuracy: 0.24\n",
      "Epoch:  16 | train loss: 0.7171 | test accuracy: 0.23\n",
      "Epoch:  17 | train loss: 0.7201 | test accuracy: 0.26\n",
      "Epoch:  18 | train loss: 0.7168 | test accuracy: 0.26\n",
      "Epoch:  19 | train loss: 0.7084 | test accuracy: 0.22\n",
      "Epoch:  20 | train loss: 0.6881 | test accuracy: 0.24\n",
      "Epoch:  21 | train loss: 0.6891 | test accuracy: 0.23\n",
      "Epoch:  22 | train loss: 0.6926 | test accuracy: 0.26\n",
      "Epoch:  23 | train loss: 0.6881 | test accuracy: 0.25\n",
      "Epoch:  24 | train loss: 0.6811 | test accuracy: 0.27\n",
      "Epoch:  25 | train loss: 0.7044 | test accuracy: 0.27\n",
      "Epoch:  26 | train loss: 0.6914 | test accuracy: 0.21\n",
      "Epoch:  27 | train loss: 0.7001 | test accuracy: 0.25\n",
      "Epoch:  28 | train loss: 0.6905 | test accuracy: 0.27\n",
      "Epoch:  29 | train loss: 0.6990 | test accuracy: 0.22\n",
      "Epoch:  30 | train loss: 0.7160 | test accuracy: 0.20\n",
      "Epoch:  31 | train loss: 0.7140 | test accuracy: 0.26\n",
      "Epoch:  32 | train loss: 0.6708 | test accuracy: 0.22\n",
      "Epoch:  33 | train loss: 0.7151 | test accuracy: 0.22\n",
      "Epoch:  34 | train loss: 0.6906 | test accuracy: 0.26\n",
      "Epoch:  35 | train loss: 0.7058 | test accuracy: 0.25\n",
      "Epoch:  36 | train loss: 0.6913 | test accuracy: 0.24\n",
      "Epoch:  37 | train loss: 0.6926 | test accuracy: 0.22\n",
      "Epoch:  38 | train loss: 0.7088 | test accuracy: 0.25\n",
      "Epoch:  39 | train loss: 0.7008 | test accuracy: 0.26\n",
      "Epoch:  40 | train loss: 0.7039 | test accuracy: 0.24\n",
      "Epoch:  41 | train loss: 0.6990 | test accuracy: 0.23\n",
      "Epoch:  42 | train loss: 0.6974 | test accuracy: 0.19\n",
      "Epoch:  43 | train loss: 0.6898 | test accuracy: 0.28\n",
      "Epoch:  44 | train loss: 0.6906 | test accuracy: 0.23\n",
      "Epoch:  45 | train loss: 0.6779 | test accuracy: 0.28\n",
      "Epoch:  46 | train loss: 0.6880 | test accuracy: 0.25\n",
      "Epoch:  47 | train loss: 0.6909 | test accuracy: 0.27\n",
      "Epoch:  48 | train loss: 0.7021 | test accuracy: 0.28\n",
      "Epoch:  49 | train loss: 0.7090 | test accuracy: 0.16\n",
      "Epoch:  0 | train loss: 0.7099 | test accuracy: 0.20\n",
      "Epoch:  1 | train loss: 0.6995 | test accuracy: 0.23\n",
      "Epoch:  2 | train loss: 0.6874 | test accuracy: 0.24\n",
      "Epoch:  3 | train loss: 0.7021 | test accuracy: 0.23\n",
      "Epoch:  4 | train loss: 0.6869 | test accuracy: 0.24\n",
      "Epoch:  5 | train loss: 0.7166 | test accuracy: 0.21\n",
      "Epoch:  6 | train loss: 0.7179 | test accuracy: 0.22\n",
      "Epoch:  7 | train loss: 0.6896 | test accuracy: 0.26\n",
      "Epoch:  8 | train loss: 0.7153 | test accuracy: 0.24\n",
      "Epoch:  9 | train loss: 0.6924 | test accuracy: 0.23\n",
      "Epoch:  10 | train loss: 0.6989 | test accuracy: 0.22\n",
      "Epoch:  11 | train loss: 0.7104 | test accuracy: 0.20\n",
      "Epoch:  12 | train loss: 0.7051 | test accuracy: 0.22\n",
      "Epoch:  13 | train loss: 0.6862 | test accuracy: 0.21\n",
      "Epoch:  14 | train loss: 0.6880 | test accuracy: 0.21\n",
      "Epoch:  15 | train loss: 0.6831 | test accuracy: 0.26\n",
      "Epoch:  16 | train loss: 0.7059 | test accuracy: 0.21\n",
      "Epoch:  17 | train loss: 0.7335 | test accuracy: 0.28\n",
      "Epoch:  18 | train loss: 0.6932 | test accuracy: 0.26\n",
      "Epoch:  19 | train loss: 0.6803 | test accuracy: 0.24\n",
      "Epoch:  20 | train loss: 0.6905 | test accuracy: 0.24\n",
      "Epoch:  21 | train loss: 0.7022 | test accuracy: 0.25\n",
      "Epoch:  22 | train loss: 0.6863 | test accuracy: 0.26\n",
      "Epoch:  23 | train loss: 0.7028 | test accuracy: 0.26\n",
      "Epoch:  24 | train loss: 0.6890 | test accuracy: 0.28\n",
      "Epoch:  25 | train loss: 0.6795 | test accuracy: 0.26\n",
      "Epoch:  26 | train loss: 0.6983 | test accuracy: 0.26\n",
      "Epoch:  27 | train loss: 0.6925 | test accuracy: 0.23\n",
      "Epoch:  28 | train loss: 0.7026 | test accuracy: 0.26\n",
      "Epoch:  29 | train loss: 0.6809 | test accuracy: 0.26\n",
      "Epoch:  30 | train loss: 0.7148 | test accuracy: 0.28\n",
      "Epoch:  31 | train loss: 0.7099 | test accuracy: 0.23\n",
      "Epoch:  32 | train loss: 0.6984 | test accuracy: 0.27\n",
      "Epoch:  33 | train loss: 0.6833 | test accuracy: 0.25\n",
      "Epoch:  34 | train loss: 0.7138 | test accuracy: 0.24\n",
      "Epoch:  35 | train loss: 0.7017 | test accuracy: 0.23\n",
      "Epoch:  36 | train loss: 0.7007 | test accuracy: 0.22\n",
      "Epoch:  37 | train loss: 0.7025 | test accuracy: 0.31\n",
      "Epoch:  38 | train loss: 0.6842 | test accuracy: 0.25\n",
      "Epoch:  39 | train loss: 0.7004 | test accuracy: 0.25\n",
      "Epoch:  40 | train loss: 0.6986 | test accuracy: 0.21\n",
      "Epoch:  41 | train loss: 0.7171 | test accuracy: 0.27\n",
      "Epoch:  42 | train loss: 0.6908 | test accuracy: 0.27\n",
      "Epoch:  43 | train loss: 0.6896 | test accuracy: 0.23\n",
      "Epoch:  44 | train loss: 0.7099 | test accuracy: 0.22\n",
      "Epoch:  45 | train loss: 0.7067 | test accuracy: 0.22\n",
      "Epoch:  46 | train loss: 0.6875 | test accuracy: 0.22\n",
      "Epoch:  47 | train loss: 0.6856 | test accuracy: 0.29\n",
      "Epoch:  48 | train loss: 0.6793 | test accuracy: 0.26\n",
      "Epoch:  49 | train loss: 0.6962 | test accuracy: 0.28\n",
      "Epoch:  0 | train loss: 0.6980 | test accuracy: 0.21\n",
      "Epoch:  1 | train loss: 0.6808 | test accuracy: 0.28\n",
      "Epoch:  2 | train loss: 0.7189 | test accuracy: 0.29\n",
      "Epoch:  3 | train loss: 0.6963 | test accuracy: 0.29\n",
      "Epoch:  4 | train loss: 0.7436 | test accuracy: 0.26\n",
      "Epoch:  5 | train loss: 0.7140 | test accuracy: 0.22\n",
      "Epoch:  6 | train loss: 0.7204 | test accuracy: 0.25\n",
      "Epoch:  7 | train loss: 0.6890 | test accuracy: 0.22\n",
      "Epoch:  8 | train loss: 0.7130 | test accuracy: 0.24\n",
      "Epoch:  9 | train loss: 0.7075 | test accuracy: 0.25\n",
      "Epoch:  10 | train loss: 0.7065 | test accuracy: 0.24\n",
      "Epoch:  11 | train loss: 0.6969 | test accuracy: 0.24\n",
      "Epoch:  12 | train loss: 0.7056 | test accuracy: 0.33\n",
      "Epoch:  13 | train loss: 0.7101 | test accuracy: 0.24\n",
      "Epoch:  14 | train loss: 0.6876 | test accuracy: 0.27\n",
      "Epoch:  15 | train loss: 0.6868 | test accuracy: 0.21\n",
      "Epoch:  16 | train loss: 0.6864 | test accuracy: 0.28\n",
      "Epoch:  17 | train loss: 0.7103 | test accuracy: 0.24\n",
      "Epoch:  18 | train loss: 0.6740 | test accuracy: 0.29\n",
      "Epoch:  19 | train loss: 0.6854 | test accuracy: 0.25\n",
      "Epoch:  20 | train loss: 0.6942 | test accuracy: 0.24\n",
      "Epoch:  21 | train loss: 0.7038 | test accuracy: 0.26\n",
      "Epoch:  22 | train loss: 0.7105 | test accuracy: 0.22\n",
      "Epoch:  23 | train loss: 0.7182 | test accuracy: 0.24\n",
      "Epoch:  24 | train loss: 0.7053 | test accuracy: 0.26\n",
      "Epoch:  25 | train loss: 0.7192 | test accuracy: 0.24\n",
      "Epoch:  26 | train loss: 0.6963 | test accuracy: 0.25\n",
      "Epoch:  27 | train loss: 0.7187 | test accuracy: 0.25\n",
      "Epoch:  28 | train loss: 0.7092 | test accuracy: 0.24\n",
      "Epoch:  29 | train loss: 0.6924 | test accuracy: 0.26\n",
      "Epoch:  30 | train loss: 0.7241 | test accuracy: 0.24\n",
      "Epoch:  31 | train loss: 0.7111 | test accuracy: 0.26\n",
      "Epoch:  32 | train loss: 0.6972 | test accuracy: 0.26\n",
      "Epoch:  33 | train loss: 0.6929 | test accuracy: 0.23\n",
      "Epoch:  34 | train loss: 0.6827 | test accuracy: 0.28\n",
      "Epoch:  35 | train loss: 0.6809 | test accuracy: 0.24\n",
      "Epoch:  36 | train loss: 0.7105 | test accuracy: 0.26\n",
      "Epoch:  37 | train loss: 0.6908 | test accuracy: 0.25\n",
      "Epoch:  38 | train loss: 0.7092 | test accuracy: 0.25\n",
      "Epoch:  39 | train loss: 0.6961 | test accuracy: 0.21\n",
      "Epoch:  40 | train loss: 0.6986 | test accuracy: 0.27\n",
      "Epoch:  41 | train loss: 0.7022 | test accuracy: 0.23\n",
      "Epoch:  42 | train loss: 0.7182 | test accuracy: 0.24\n",
      "Epoch:  43 | train loss: 0.6853 | test accuracy: 0.25\n",
      "Epoch:  44 | train loss: 0.6804 | test accuracy: 0.22\n",
      "Epoch:  45 | train loss: 0.6803 | test accuracy: 0.24\n",
      "Epoch:  46 | train loss: 0.6906 | test accuracy: 0.26\n",
      "Epoch:  47 | train loss: 0.7183 | test accuracy: 0.25\n",
      "Epoch:  48 | train loss: 0.7056 | test accuracy: 0.27\n",
      "Epoch:  49 | train loss: 0.7047 | test accuracy: 0.21\n",
      "Epoch:  0 | train loss: 0.7298 | test accuracy: 0.25\n",
      "Epoch:  1 | train loss: 0.6997 | test accuracy: 0.28\n",
      "Epoch:  2 | train loss: 0.6892 | test accuracy: 0.26\n",
      "Epoch:  3 | train loss: 0.7057 | test accuracy: 0.26\n",
      "Epoch:  4 | train loss: 0.6787 | test accuracy: 0.27\n",
      "Epoch:  5 | train loss: 0.7033 | test accuracy: 0.20\n",
      "Epoch:  6 | train loss: 0.6913 | test accuracy: 0.19\n",
      "Epoch:  7 | train loss: 0.6821 | test accuracy: 0.26\n",
      "Epoch:  8 | train loss: 0.7109 | test accuracy: 0.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9 | train loss: 0.7239 | test accuracy: 0.22\n",
      "Epoch:  10 | train loss: 0.6695 | test accuracy: 0.25\n",
      "Epoch:  11 | train loss: 0.6931 | test accuracy: 0.24\n",
      "Epoch:  12 | train loss: 0.7008 | test accuracy: 0.26\n",
      "Epoch:  13 | train loss: 0.7016 | test accuracy: 0.26\n",
      "Epoch:  14 | train loss: 0.6938 | test accuracy: 0.25\n",
      "Epoch:  15 | train loss: 0.6881 | test accuracy: 0.25\n",
      "Epoch:  16 | train loss: 0.6990 | test accuracy: 0.25\n",
      "Epoch:  17 | train loss: 0.6908 | test accuracy: 0.21\n",
      "Epoch:  18 | train loss: 0.6650 | test accuracy: 0.24\n",
      "Epoch:  19 | train loss: 0.7048 | test accuracy: 0.22\n",
      "Epoch:  20 | train loss: 0.6868 | test accuracy: 0.24\n",
      "Epoch:  21 | train loss: 0.6996 | test accuracy: 0.27\n",
      "Epoch:  22 | train loss: 0.7108 | test accuracy: 0.24\n",
      "Epoch:  23 | train loss: 0.6950 | test accuracy: 0.25\n",
      "Epoch:  24 | train loss: 0.7071 | test accuracy: 0.26\n",
      "Epoch:  25 | train loss: 0.7061 | test accuracy: 0.26\n",
      "Epoch:  26 | train loss: 0.6821 | test accuracy: 0.27\n",
      "Epoch:  27 | train loss: 0.7001 | test accuracy: 0.22\n",
      "Epoch:  28 | train loss: 0.6951 | test accuracy: 0.26\n",
      "Epoch:  29 | train loss: 0.6997 | test accuracy: 0.24\n",
      "Epoch:  30 | train loss: 0.6995 | test accuracy: 0.24\n",
      "Epoch:  31 | train loss: 0.6911 | test accuracy: 0.22\n",
      "Epoch:  32 | train loss: 0.6771 | test accuracy: 0.30\n",
      "Epoch:  33 | train loss: 0.6827 | test accuracy: 0.23\n",
      "Epoch:  34 | train loss: 0.7080 | test accuracy: 0.22\n",
      "Epoch:  35 | train loss: 0.7156 | test accuracy: 0.23\n",
      "Epoch:  36 | train loss: 0.6911 | test accuracy: 0.27\n",
      "Epoch:  37 | train loss: 0.7068 | test accuracy: 0.25\n",
      "Epoch:  38 | train loss: 0.7045 | test accuracy: 0.25\n",
      "Epoch:  39 | train loss: 0.6904 | test accuracy: 0.22\n",
      "Epoch:  40 | train loss: 0.7020 | test accuracy: 0.27\n",
      "Epoch:  41 | train loss: 0.7065 | test accuracy: 0.24\n",
      "Epoch:  42 | train loss: 0.7066 | test accuracy: 0.21\n",
      "Epoch:  43 | train loss: 0.7085 | test accuracy: 0.24\n",
      "Epoch:  44 | train loss: 0.7168 | test accuracy: 0.22\n",
      "Epoch:  45 | train loss: 0.6838 | test accuracy: 0.26\n",
      "Epoch:  46 | train loss: 0.7074 | test accuracy: 0.26\n",
      "Epoch:  47 | train loss: 0.6857 | test accuracy: 0.26\n",
      "Epoch:  48 | train loss: 0.7061 | test accuracy: 0.23\n",
      "Epoch:  49 | train loss: 0.6953 | test accuracy: 0.26\n",
      "Epoch:  0 | train loss: 0.6990 | test accuracy: 0.25\n",
      "Epoch:  1 | train loss: 0.6964 | test accuracy: 0.23\n",
      "Epoch:  2 | train loss: 0.7172 | test accuracy: 0.28\n",
      "Epoch:  3 | train loss: 0.6870 | test accuracy: 0.32\n",
      "Epoch:  4 | train loss: 0.7084 | test accuracy: 0.20\n",
      "Epoch:  5 | train loss: 0.6987 | test accuracy: 0.20\n",
      "Epoch:  6 | train loss: 0.6912 | test accuracy: 0.24\n",
      "Epoch:  7 | train loss: 0.7197 | test accuracy: 0.24\n",
      "Epoch:  8 | train loss: 0.6934 | test accuracy: 0.27\n",
      "Epoch:  9 | train loss: 0.7011 | test accuracy: 0.26\n",
      "Epoch:  10 | train loss: 0.7104 | test accuracy: 0.22\n",
      "Epoch:  11 | train loss: 0.7064 | test accuracy: 0.24\n",
      "Epoch:  12 | train loss: 0.7008 | test accuracy: 0.25\n",
      "Epoch:  13 | train loss: 0.7345 | test accuracy: 0.22\n",
      "Epoch:  14 | train loss: 0.7004 | test accuracy: 0.25\n",
      "Epoch:  15 | train loss: 0.6786 | test accuracy: 0.24\n",
      "Epoch:  16 | train loss: 0.6935 | test accuracy: 0.25\n",
      "Epoch:  17 | train loss: 0.6881 | test accuracy: 0.23\n",
      "Epoch:  18 | train loss: 0.7263 | test accuracy: 0.27\n",
      "Epoch:  19 | train loss: 0.6981 | test accuracy: 0.22\n",
      "Epoch:  20 | train loss: 0.6927 | test accuracy: 0.28\n",
      "Epoch:  21 | train loss: 0.7002 | test accuracy: 0.26\n",
      "Epoch:  22 | train loss: 0.6924 | test accuracy: 0.26\n",
      "Epoch:  23 | train loss: 0.6990 | test accuracy: 0.25\n",
      "Epoch:  24 | train loss: 0.6743 | test accuracy: 0.23\n",
      "Epoch:  25 | train loss: 0.7071 | test accuracy: 0.19\n",
      "Epoch:  26 | train loss: 0.6861 | test accuracy: 0.23\n",
      "Epoch:  27 | train loss: 0.6986 | test accuracy: 0.23\n",
      "Epoch:  28 | train loss: 0.7386 | test accuracy: 0.29\n",
      "Epoch:  29 | train loss: 0.7053 | test accuracy: 0.24\n",
      "Epoch:  30 | train loss: 0.6922 | test accuracy: 0.21\n",
      "Epoch:  31 | train loss: 0.6895 | test accuracy: 0.27\n",
      "Epoch:  32 | train loss: 0.6937 | test accuracy: 0.24\n",
      "Epoch:  33 | train loss: 0.7117 | test accuracy: 0.24\n",
      "Epoch:  34 | train loss: 0.7081 | test accuracy: 0.23\n",
      "Epoch:  35 | train loss: 0.7228 | test accuracy: 0.25\n",
      "Epoch:  36 | train loss: 0.7086 | test accuracy: 0.20\n",
      "Epoch:  37 | train loss: 0.7084 | test accuracy: 0.25\n",
      "Epoch:  38 | train loss: 0.7035 | test accuracy: 0.24\n",
      "Epoch:  39 | train loss: 0.7072 | test accuracy: 0.26\n",
      "Epoch:  40 | train loss: 0.7073 | test accuracy: 0.26\n",
      "Epoch:  41 | train loss: 0.7187 | test accuracy: 0.27\n",
      "Epoch:  42 | train loss: 0.7085 | test accuracy: 0.25\n",
      "Epoch:  43 | train loss: 0.7043 | test accuracy: 0.23\n",
      "Epoch:  44 | train loss: 0.6859 | test accuracy: 0.23\n",
      "Epoch:  45 | train loss: 0.7117 | test accuracy: 0.24\n",
      "Epoch:  46 | train loss: 0.6759 | test accuracy: 0.28\n",
      "Epoch:  47 | train loss: 0.6986 | test accuracy: 0.23\n",
      "Epoch:  48 | train loss: 0.7237 | test accuracy: 0.24\n",
      "Epoch:  49 | train loss: 0.6959 | test accuracy: 0.28\n",
      "771 ms ± 44 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for epoch in range(EPOCH):   # 训练所有!整套!数据 50000次\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        output = net2(batch_x)               #  output\n",
    "        loss = loss_func(output, batch_y)   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "        if step % 500 == 0:\n",
    "            test_output = net2(test_x)                   # (samples, time_step, input_size)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "            accuracy = float((pred_y == test_y).astype(int).sum()) / float(test_y.size)\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation (sigmoid) function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))\n",
    "def error_formula(y, output):\n",
    "    return - y*np.log(output) - (1 - y) * np.log(1-output)\n",
    "def error_term_formula(x, y, output):\n",
    "    return (y - output)*sigmoid_prime(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network hyperparameters\n",
    "epochs = 1000\n",
    "learnrate = 0.5\n",
    "\n",
    "# Training function\n",
    "def train_nn(features, targets, epochs, learnrate):\n",
    "    \n",
    "    # Use to same seed to make debugging easier\n",
    "    np.random.seed(42)\n",
    "\n",
    "    n_records, n_features = features.shape\n",
    "    last_loss = None\n",
    "\n",
    "    # Initialize weights\n",
    "    weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        del_w = np.zeros(weights.shape)\n",
    "        for x, y in zip(features.values, targets):\n",
    "            # Loop through all records, x is the input, y is the target\n",
    "\n",
    "            # Activation of the output unit\n",
    "            #   Notice we multiply the inputs and the weights here \n",
    "            #   rather than storing h as a separate variable \n",
    "            output = sigmoid(np.dot(x, weights))\n",
    "\n",
    "            # The error, the target minus the network output\n",
    "            error = error_formula(y, output)\n",
    "\n",
    "            # The error term\n",
    "            error_term = error_term_formula(x, y, output)\n",
    "\n",
    "            # The gradient descent step, the error times the gradient times the inputs\n",
    "            del_w += error_term * x\n",
    "\n",
    "        # Update the weights here. The learning rate times the \n",
    "        # change in weights, divided by the number of records to average\n",
    "        weights += learnrate * del_w / n_records\n",
    "\n",
    "        # Printing out the mean square error on the training set\n",
    "        if e % (epochs / 10) == 0:\n",
    "            out = sigmoid(np.dot(features, weights))\n",
    "            loss = np.mean((out - targets) ** 2)\n",
    "            print(\"Epoch:\", e)\n",
    "            if last_loss and last_loss < loss:\n",
    "                print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "            else:\n",
    "                print(\"Train loss: \", loss)\n",
    "            last_loss = loss\n",
    "            print(\"=========\")\n",
    "    print(\"Finished training!\")\n",
    "    return weights\n",
    "    \n",
    "#weights = train_nn(features, targets, epochs, learnrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy on test data\n",
    "test_out = sigmoid(np.dot(features_test, weights))\n",
    "predictions = test_out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
